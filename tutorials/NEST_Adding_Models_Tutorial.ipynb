{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the NEST Model Integration Tutorial\n",
        "\n",
        "This tutorial will guide you through the process of **adding new models** to the **Neural Encoding Simulation Toolkit (NEST)** — a toolbox consisting of trained encoding models of the brain that you can use to generate in silico neural responses to stimuli of your choice.\n",
        "\n",
        "The code used to create NEST, along with its utility functions, is available on [GitHub][github].\n",
        "\n",
        "Whether you're contributing a model for **fMRI**, **EEG**, or a **new modality**, this tutorial walks you through each required step, with hands-on examples and best practices.\n",
        "\n",
        "If you use the code and/or data from this tutorial, please cite:\n",
        "\n",
        "> *Gifford AT, Bersch D, Roig G, Cichy RM. 2025. The Neural Encoding Simulation Toolkit. In preparation. https://github.com/gifale95/NEST*\n",
        "\n",
        "\n",
        "\n",
        "[nest]: https://www.alegifford.com/projects/nest/\n",
        "[data_manual]: https://docs.google.com/document/d/1DeQwjq96pTkPEnqv7V6q9g_NTHCjc6aYr6y3wPlwgDE/edit?usp=drive_link\n",
        "[github]: https://github.com/gifale95/NEST\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### What You Will Learn\n",
        "\n",
        "We will cover:\n",
        "\n",
        "1. **Overview**  \n",
        "2. **Quick Start: Model Implementation Template**  \n",
        "3. **Detailed Implementation Guide**  \n",
        "   - 3.1: Determining Your Model's Location  \n",
        "   - 3.2: Creating the YAML Configuration File  \n",
        "   - 3.3: Implementing the Model Class  \n",
        "     - 3.3.1: Model Registration  \n",
        "     - 3.3.2: Class Initialization and Parameter Validation  \n",
        "     - 3.3.3: Loading the Model  \n",
        "     - 3.3.4: Generating Responses  \n",
        "     - 3.3.5: Accessing Metadata  \n",
        "     - 3.3.6: Auxiliary Methods  \n",
        "     - 3.3.7: Complete Implementation Example  \n",
        "4. **Adding a New Modality**  \n",
        "5. **Contributing to NEST**\n",
        "\n",
        "\n",
        "\n",
        "By the end of this tutorial, you will be able to plug your model into NEST and use it to generate in silico neural responses to arbitrary stimuli.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Overview\n",
        "\n",
        "Adding a new model to NEST requires creating two main files:\n",
        "\n",
        "1. **A Python model file** — implements the model’s logic and interface  \n",
        "2. **A YAML configuration file** — describes the model’s parameters and behavior\n",
        "\n",
        "These two files work together to register your model with NEST and make it accessible through the unified interface.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Quick Start: Model Implementation Template\n",
        "\n",
        "Here's a barebones version of a Python model file that shows only the required structure.  \n",
        "We will expand on this template throughout the tutorial to build a fully functional model.\n",
        "\n",
        "You can use this as a starting point and fill in the details specific to your model.\n",
        "\n",
        "\n",
        "```python\n",
        "from nest.interfaces.base_model import BaseModelInterface\n",
        "from nest.core.model_registry import register_model\n",
        "\n",
        "# Load model info from YAML\n",
        "def load_model_info():\n",
        "    path = os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",
        "    with open(path, \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "model_info = load_model_info()\n",
        "\n",
        "register_model(\n",
        "    model_id=model_info[\"model_id\"],\n",
        "    module_path=\"nest.models.your_modality.your_model_file\",\n",
        "    class_name=\"YourModelClass\",\n",
        "    modality=model_info[\"modality\"],\n",
        "    dataset=model_info[\"dataset\"],\n",
        "    yaml_path=os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",
        ")\n",
        "\n",
        "class YourModelClass(BaseModelInterface):\n",
        "    def __init__(self, subject, device=\"auto\", nest_dir=None, **kwargs):\n",
        "        # Set up model parameters and device\n",
        "        pass\n",
        "\n",
        "    def load_model(self):\n",
        "        # Load model weights and prepare for inference\n",
        "        pass\n",
        "\n",
        "    def generate_response(self, stimulus, **kwargs):\n",
        "        # Generate simulated neural responses\n",
        "        pass\n",
        "\n",
        "    def get_metadata(self):\n",
        "        # Return model metadata\n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def get_model_id(cls):\n",
        "        # Return the model ID string\n",
        "        pass\n",
        "\n",
        "    def cleanup(self):\n",
        "        # Free up any resources (e.g., GPU memory)\n",
        "        pass\n",
        "```\n",
        "\n",
        "This is the required structure. Each method must be implemented for your model to work with NEST.\n"
      ],
      "metadata": {
        "id": "2903FrDpACVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. How to Implement a New Model into NEST\n",
        "\n",
        "This step-by-step guide walks you through the process of implementing a complete model, starting from the barebones template shown above.\n",
        "\n",
        "We will cover the following topics:\n",
        "\n",
        "1. **Determining where your model belongs in the NEST structure**\n",
        "2. **Creating the YAML configuration file**\n",
        "3. **Implementing the model class with all required components:**\n",
        "   - Model registration  \n",
        "   - Initialization and parameter validation  \n",
        "   - Model loading  \n",
        "   - Response generation  \n",
        "   - Metadata access  \n",
        "   - Resource cleanup  \n"
      ],
      "metadata": {
        "id": "4n3VUrd1MnSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1: Where Does Your Model Belong?\n",
        "\n",
        "First, determine which **modality** your model belongs to:\n",
        "\n",
        "- If it's an **fMRI model**, add it to:  \n",
        "  `nest/models/fmri/`\n",
        "\n",
        "- If it's an **EEG model**, add it to:  \n",
        "  `nest/models/eeg/`\n",
        "\n",
        "- If it's a **new modality**, create a new directory:  \n",
        "  `nest/models/your_new_modality/`\n",
        "\n",
        "  > **Note**: If you are adding a new modality, there are a few additional considerations. These are discussed in **Step 4** below.\n",
        "\n",
        "Your corresponding **YAML configuration file** should go here:  \n",
        "`nest/models/model_cards/your_model_id.yaml`"
      ],
      "metadata": {
        "id": "nk4SHF9T8YEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 3.2: Creating the YAML Configuration File\n",
        "\n",
        "In the NEST toolkit, you'll find a template YAML file at: `nest/models/model_cards/template.yaml`\n",
        "\n",
        "\n",
        "This template serves as a guide for creating your model's configuration.\n",
        "\n",
        "Your YAML file is **crucial** because it:\n",
        "\n",
        "- Provides metadata about your model  \n",
        "- Defines input/output specifications  \n",
        "- Documents valid parameters and constraints  \n",
        "- Is used for parameter validation in your model class  \n",
        "- Generates model cards for end users  \n",
        "\n",
        "> Be as detailed as possible — this helps others understand how to work with your model.  \n",
        "> **You can reference existing model YAML files as examples.**\n",
        "\n",
        "Here's what you need to include:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S9QlN874PGAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```yaml\n",
        "# Template YAML file for NEST model specification\n",
        "# Replace placeholder values with actual model information\n",
        "\n",
        "# Basic metadata\n",
        "model_id: modality_dataset_model_type  # e.g., fmri_nsd_fwrf\n",
        "modality: modality  # e.g., fmri, eeg, meg, ...\n",
        "dataset: dataset_name\n",
        "features: feature_extraction_method\n",
        "repeats: single/multi  # whether model generates single or multiple repetitions\n",
        "subject_specific: true/false  # whether model is subject-specific\n",
        "\n",
        "# General description of the model\n",
        "description: |\n",
        "  Provide a concise but informative description of the model, including:\n",
        "   - What kind of neural responses it generates\n",
        "   - What dataset it was trained on\n",
        "   - The basic approach/architecture\n",
        "   - Any notable characteristics or limitations\n",
        "   Keep this to 3-5 sentences for readability.\n",
        "\n",
        "# Input stimulus information\n",
        "input:\n",
        "  type: \"numpy.ndarray\"  # or other appropriate type\n",
        "  shape: [shape_description]  # e.g., [batch_size, 3, height, width]\n",
        "  description: \"Brief description of input format\"\n",
        "  constraints:\n",
        "    - \"List any constraints on input values\"\n",
        "    - \"e.g., value ranges, size requirements, etc.\"\n",
        "\n",
        "# Output information\n",
        "output:\n",
        "  type: \"numpy.ndarray\"  # or other appropriate type\n",
        "  shape: [shape_description]  # e.g., [batch_size, n_voxels]\n",
        "  description: \"Brief description of output format\"\n",
        "  dimensions:\n",
        "    - name: \"dimension_name\"\n",
        "      description: \"What this dimension represents\"\n",
        "    - name: \"dimension_name\"\n",
        "      description: \"What this dimension represents\"\n",
        "    # Add more dimensions as needed\n",
        "\n",
        "# Model parameters and their usage\n",
        "parameters:\n",
        "  # First parameter (typically subject)\n",
        "  param_name:\n",
        "    type: param_type  # e.g., int, str, float\n",
        "    required: true/false\n",
        "    valid_values: list_of_valid_values  # or range, or omit if not applicable\n",
        "    default: default_value  # include if there's a default value\n",
        "    example: example_value\n",
        "    description: \"Description of what this parameter represents\"\n",
        "    function: \"Which function uses this parameter: get_encoding_model, load_model, ..\"\n",
        "  \n",
        "  # Add more parameters as needed\n",
        "  param_name:\n",
        "    type: param_type\n",
        "    required: true/false\n",
        "    valid_values: list_of_valid_values  # or range, or omit if not applicable\n",
        "    default: default_value  # include if there's a default value\n",
        "    example: example_value\n",
        "    description: \"Description of what this parameter represents\"\n",
        "    function: \"Which function uses this parameter\"\n",
        "\n",
        "# Performance metrics (if needed) and references\n",
        "performance:\n",
        "  metrics:\n",
        "    - name: \"metric_name\"\n",
        "      value: \"metric_value\"\n",
        "      description: \"What this metric represents\"\n",
        "    \n",
        "    # Add more metrics as needed\n",
        "    - name: \"metric_name\"\n",
        "      value: \"metric_value\"\n",
        "      description: \"What this metric represents\"\n",
        "  \n",
        "  plots: \"URL_to_performance_plots\"  # URL or path to visualizations\n",
        "\n",
        "# Add References here\n",
        "references:\n",
        "    - \"Citation for your model or dataset\"\n",
        "```"
      ],
      "metadata": {
        "id": "ld8ZojZNPghr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3: Implementing the Model Class\n",
        "\n",
        "Now we'll build the complete model implementation step by step.  \n",
        "The required functions must be named **exactly as shown** to work with the `BaseModelInterface`.\n",
        "\n",
        "You are free to add additional helper functions as needed — but the core methods must be implemented.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "YsPKENefR2GG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1: Model Registration\n",
        "\n",
        "First, set up the model registration code that makes your model discoverable by the NEST toolkit.\n",
        "\n",
        "This code:\n",
        "\n",
        "1. Loads your model's configuration from the YAML file  \n",
        "2. Registers your model with the NEST registry, making it discoverable  \n",
        "3. Specifies the module path, class name, and modality"
      ],
      "metadata": {
        "id": "Ax7ne30Ez-jf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import os\n",
        "import yaml\n",
        "from nest.core.model_registry import register_model\n",
        "\n",
        "\n",
        "# Load model info from YAML\n",
        "def load_model_info():\n",
        "    yaml_path = os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",
        "    with open(os.path.abspath(yaml_path), \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# Load model_info once at the top\n",
        "model_info = load_model_info()\n",
        "\n",
        "# Register this model with the registry using model_info\n",
        "register_model(\n",
        "    model_id=model_info[\"model_id\"],\n",
        "    module_path=\"nest.models.your_modality.your_model_file\",  # Replace with actual path\n",
        "    class_name=\"YourModelClass\",\n",
        "    modality=model_info.get(\"modality\", \"your_modality\"),\n",
        "    dataset=model_info.get(\"dataset\", \"your_dataset\"),\n",
        "    yaml_path=os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "dofNplJfdjDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 3.3.2: Class Initialization and Parameter Validation\n",
        "\n",
        "Next, define your model class by inheriting from `BaseModelInterface` and implement the initialization logic.\n",
        "\n",
        "The initialization method:\n",
        "\n",
        "1. Stores user-provided parameters (e.g., subject ID, device, NEST directory)  \n",
        "2. Validates parameters against the specifications in the YAML file  \n",
        "3. Sets up the compute device (CPU or GPU)  \n",
        "4. Can process additional model-specific parameters through `**kwargs`"
      ],
      "metadata": {
        "id": "dWnvGCZo0Jz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "class YourModelClass(BaseModelInterface):\n",
        "    \"\"\"\n",
        "    Your model description here. Explain what this model does, what\n",
        "    neural responses it generates, and any other important details.\n",
        "    \"\"\"\n",
        "    \n",
        "    MODEL_ID = model_info[\"model_id\"]\n",
        "    # Extract any validation info from model_info\n",
        "    VALID_SUBJECTS = model_info[\"parameters\"][\"subject\"][\"valid_values\"]\n",
        "    \n",
        "    def __init__(self, subject: int, device: str = \"auto\", nest_dir: Optional[str] = None, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize your model with the required parameters.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        subject : int\n",
        "            Subject ID for subject-specific models.\n",
        "        device : str\n",
        "            Device to run the model on ('cpu', 'cuda', or 'auto').\n",
        "        nest_dir : str, optional\n",
        "            Path to the NEST directory.\n",
        "        **kwargs\n",
        "            Additional model-specific parameters.\n",
        "        \"\"\"\n",
        "        self.subject = subject\n",
        "        self.nest_dir = nest_dir\n",
        "        self.model = None\n",
        "        self._validate_parameters()\n",
        "        \n",
        "        # Select device\n",
        "        if device == \"auto\":\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.device = device\n",
        "        \n",
        "        # Store any additional parameters\n",
        "        # self.your_param = kwargs.get('your_param', default_value)\n",
        "\n",
        "    def _validate_parameters(self):\n",
        "        \"\"\"\n",
        "        Validate the input parameters against the model specs.\n",
        "        \"\"\"\n",
        "        if self.subject not in self.VALID_SUBJECTS:\n",
        "            raise InvalidParameterError(\n",
        "                f\"Subject must be one of {self.VALID_SUBJECTS}, got {self.subject}\"\n",
        "            )\n",
        "        \n",
        "        # Add any other parameter validation here\n",
        "```"
      ],
      "metadata": {
        "id": "fNM7j5cph8kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.3.3: Loading the Model\n",
        "\n",
        "Next, implement the `load_model()` method, which handles loading model weights and preparing the model for inference.\n",
        "\n",
        "This method:\n",
        "\n",
        "1. Constructs the file path to your model weights using a consistent directory structure  \n",
        "2. Loads the model architecture and weights (implementation will vary based on your model type)  \n",
        "3. Moves the model to the appropriate device (CPU or GPU)  \n",
        "4. Sets the model to evaluation mode  \n",
        "5. Stores the loaded model in a class variable (e.g., `self.model`) for use by other methods\n",
        "\n",
        "> Remember to customize the model loading code for your specific architecture and framework (e.g., PyTorch, TensorFlow, etc.).\n",
        "\n"
      ],
      "metadata": {
        "id": "pTiyAfrv0OWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "\n",
        "    def load_model(self) -> None:\n",
        "        \"\"\"\n",
        "        Load model weights and prepare for inference.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Build paths to model weights\n",
        "            weights_path = os.path.join(\n",
        "                self.nest_dir,\n",
        "                'your_path') # Adjust filename format as needed\n",
        "            \n",
        "            # Load your model here\n",
        "            # Example with PyTorch:\n",
        "            # self.model = YourModelArchitecture()\n",
        "            # self.model.load_state_dict(torch.load(weights_path, map_location=torch.device(self.device)))\n",
        "            # self.model.to(self.device)\n",
        "            # self.model.eval()\n",
        "            \n",
        "            print(f\"Model loaded on {self.device} for subject {self.subject}\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            raise ModelLoadError(f\"Failed to load model: {str(e)}\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "sXXdjkLgk3EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.3.4: Generating Responses\n",
        "\n",
        "The `generate_response()` method is the core functionality that produces in silico neural responses from input stimuli:\n",
        "\n",
        "This method:\n",
        "\n",
        "1. Validates the input stimulus to ensure it meets requirements  \n",
        "2. Preprocesses the stimulus if needed (e.g., normalization, resizing)  \n",
        "3. Runs the model inference, typically in batches to manage memory usage  \n",
        "4. Collects and formats the response data  \n",
        "5. Returns the in silico neural responses as a NumPy array  \n",
        "\n",
        "Customize this method based on your model's specific requirements and output format.\n",
        "\n"
      ],
      "metadata": {
        "id": "4AqmDu400QxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "    def generate_response(\n",
        "        self,\n",
        "        stimulus: np.ndarray,\n",
        "        **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate in silico neural responses for given stimuli.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        stimulus : np.ndarray\n",
        "            Input stimulus array. Typically has shape (batch_size, channels, height, width)\n",
        "            for image stimuli, but requirements vary by model.\n",
        "        **kwargs\n",
        "            Additional model-specific parameters for response generation.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Simulated neural responses. Shape depends on your model's output.\n",
        "        \"\"\"\n",
        "        # Validate stimulus\n",
        "        if not isinstance(stimulus, np.ndarray) or len(stimulus.shape) != 4:\n",
        "            raise StimulusError(\n",
        "                \"Stimulus must be a 4D numpy array (batch, channels, height, width)\"\n",
        "            )\n",
        "        \n",
        "        # Preprocess stimulus if needed\n",
        "        # preprocessed_stimulus = preprocess(stimulus)\n",
        "        \n",
        "        # Generate responses\n",
        "        # with torch.no_grad():\n",
        "        #     batch_size = 100  # Adjust as needed\n",
        "        #     responses = []\n",
        "        #     \n",
        "        #     for i in range(0, len(stimulus), batch_size):\n",
        "        #         batch = torch.from_numpy(stimulus[i:i+batch_size]).to(self.device)\n",
        "        #         output = self.model(batch)\n",
        "        #         responses.append(output.cpu().numpy())\n",
        "        #     \n",
        "        #     all_responses = np.concatenate(responses, axis=0)\n",
        "        \n",
        "        # For now, return dummy data with expected shape\n",
        "        # Replace this with your actual model inference\n",
        "        dummy_response = np.zeros((stimulus.shape[0], 100))  # Example shape\n",
        "        \n",
        "        return dummy_response\n",
        "```"
      ],
      "metadata": {
        "id": "pukmJ-rundzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.3.5: Accessing Metadata\n",
        "\n",
        "The `get_metadata()` method provides information about the model and its outputs.\n",
        "\n",
        "This method:\n",
        "\n",
        "1. Attempts to load metadata from a predefined location  \n",
        "2. Returns the metadata as a dictionary  \n",
        "3. Provides basic information if no metadata file is found  \n",
        "\n",
        "The metadata may include information about voxel indices, channel information, region details, or other model-specific information.\n",
        "\n"
      ],
      "metadata": {
        "id": "CsEkzHHX0TO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "    def get_metadata(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Return metadata about the model and its outputs.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, Any]\n",
        "            Dictionary containing model metadata.\n",
        "        \"\"\"\n",
        "        # Load metadata file if available\n",
        "        metadata_path = os.path.join(\n",
        "            self.nest_dir,\n",
        "            'your_path')\n",
        "        \n",
        "        try:\n",
        "            metadata = np.load(metadata_path, allow_pickle=True).item()\n",
        "            return metadata\n",
        "        except Exception as e:\n",
        "            # If no metadata file exists, return basic info\n",
        "            return {\n",
        "                \"model_id\": self.MODEL_ID,\n",
        "                \"subject\": self.subject,\n",
        "                # Add any other relevant metadata\n",
        "            }\n"
      ],
      "metadata": {
        "id": "6sMQ8Is4o3-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.3.6: Auxiliary Methods\n",
        "\n",
        "Finally, implement these required auxiliary methods.\n",
        "\n",
        "The `get_model_id()` method:\n",
        "\n",
        "1. Returns the unique identifier for your model  \n",
        "2. Is used by the NEST registry to identify the model  \n",
        "\n",
        "The `cleanup()` method:\n",
        "\n",
        "1. Releases resources (especially GPU memory)  \n",
        "2. Is important for preventing memory leaks when working with multiple models  \n",
        "3. Should clean up any large objects or references\n",
        "\n"
      ],
      "metadata": {
        "id": "pimREama0V23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "    @classmethod\n",
        "    def get_model_id(cls) -> str:\n",
        "        \"\"\"\n",
        "        Return the model's unique identifier.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Model ID string from the YAML config.\n",
        "        \"\"\"\n",
        "        return cls.MODEL_ID\n",
        "    \n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"\n",
        "        Release resources (e.g., GPU memory) when finished.\n",
        "        \"\"\"\n",
        "        if hasattr(self, 'model') and self.model is not None:\n",
        "            # Free GPU memory if using CUDA\n",
        "            if hasattr(self.model, 'to'):\n",
        "                self.model.to('cpu')\n",
        "            \n",
        "            # Clear references\n",
        "            self.model = None\n",
        "            \n",
        "            # Force CUDA cache clear if available\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "  ```"
      ],
      "metadata": {
        "id": "Rh_p0NzPpgBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.3.7. This is how the full model function could look like:"
      ],
      "metadata": {
        "id": "fpl76IUZxXcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhZS7Kh__-DX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "from nest.interfaces.base_model import BaseModelInterface\n",
        "from nest.core.model_registry import register_model\n",
        "from nest.core.exceptions import ModelLoadError, InvalidParameterError, StimulusError\n",
        "\n",
        "# Load model info from YAML\n",
        "def load_model_info():\n",
        "    yaml_path = os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",
        "    with open(os.path.abspath(yaml_path), \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# Load model_info once at the top\n",
        "model_info = load_model_info()\n",
        "\n",
        "# Register this model with the registry using model_info\n",
        "register_model(\n",
        "    model_id=model_info[\"model_id\"],\n",
        "    module_path=\"nest.models.your_modality.your_model_file\",  # Replace with actual path\n",
        "    class_name=\"YourModelClass\",\n",
        "    modality=model_info.get(\"modality\", \"your_modality\"),\n",
        "    dataset=model_info.get(\"dataset\", \"your_dataset\"),\n",
        "    yaml_path=os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",
        ")\n",
        "\n",
        "\n",
        "class YourModelClass(BaseModelInterface):\n",
        "    \"\"\"\n",
        "    Your model description here. Explain what this model does, what\n",
        "    neural responses it generates, and any other important details.\n",
        "    \"\"\"\n",
        "\n",
        "    MODEL_ID = model_info[\"model_id\"]\n",
        "    # Extract any validation info from model_info\n",
        "    VALID_SUBJECTS = model_info[\"parameters\"][\"subject\"][\"valid_values\"]\n",
        "\n",
        "    def __init__(self, subject: int, device: str = \"auto\", nest_dir: Optional[str] = None, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize your model with the required parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        subject : int\n",
        "            Subject ID for subject-specific models.\n",
        "        device : str\n",
        "            Device to run the model on ('cpu', 'cuda', or 'auto').\n",
        "        nest_dir : str, optional\n",
        "            Path to the NEST directory.\n",
        "        **kwargs\n",
        "            Additional model-specific parameters.\n",
        "        \"\"\"\n",
        "        self.subject = subject\n",
        "        self.nest_dir = nest_dir\n",
        "        self.model = None\n",
        "        self._validate_parameters()\n",
        "\n",
        "        # Select device\n",
        "        if device == \"auto\":\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.device = device\n",
        "\n",
        "        # Store any additional parameters\n",
        "        # self.your_param = kwargs.get('your_param', default_value)\n",
        "\n",
        "    def _validate_parameters(self):\n",
        "        \"\"\"\n",
        "        Validate the input parameters against the model specs.\n",
        "        \"\"\"\n",
        "        if self.subject not in self.VALID_SUBJECTS:\n",
        "            raise InvalidParameterError(\n",
        "                f\"Subject must be one of {self.VALID_SUBJECTS}, got {self.subject}\"\n",
        "            )\n",
        "\n",
        "        # Add any other parameter validation here\n",
        "\n",
        "    def load_model(self) -> None:\n",
        "        \"\"\"\n",
        "        Load model weights and prepare for inference.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Build paths to model weights\n",
        "            weights_path = os.path.join(\n",
        "                self.nest_dir,\n",
        "                'your_path') # Adjust filename format as needed\n",
        "\n",
        "            # Load your model here\n",
        "            # Example with PyTorch:\n",
        "            # self.model = YourModelArchitecture()\n",
        "            # self.model.load_state_dict(torch.load(weights_path, map_location=torch.device(self.device)))\n",
        "            # self.model.to(self.device)\n",
        "            # self.model.eval()\n",
        "\n",
        "            print(f\"Model loaded on {self.device} for subject {self.subject}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ModelLoadError(f\"Failed to load model: {str(e)}\")\n",
        "\n",
        "    def generate_response(\n",
        "        self,\n",
        "        stimulus: np.ndarray,\n",
        "        **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate in silico neural responses for given stimuli.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        stimulus : np.ndarray\n",
        "            Input stimulus array. Typically has shape (batch_size, channels, height, width)\n",
        "            for image stimuli, but requirements vary by model.\n",
        "        **kwargs\n",
        "            Additional model-specific parameters for response generation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Simulated neural responses. Shape depends on your model's output.\n",
        "        \"\"\"\n",
        "        # Validate stimulus\n",
        "        if not isinstance(stimulus, np.ndarray) or len(stimulus.shape) != 4:\n",
        "            raise StimulusError(\n",
        "                \"Stimulus must be a 4D numpy array (batch, channels, height, width)\"\n",
        "            )\n",
        "\n",
        "        # Preprocess stimulus if needed\n",
        "        # preprocessed_stimulus = preprocess(stimulus)\n",
        "\n",
        "        # Generate responses\n",
        "        # with torch.no_grad():\n",
        "        #     batch_size = 100  # Adjust as needed\n",
        "        #     responses = []\n",
        "        #\n",
        "        #     for i in range(0, len(stimulus), batch_size):\n",
        "        #         batch = torch.from_numpy(stimulus[i:i+batch_size]).to(self.device)\n",
        "        #         output = self.model(batch)\n",
        "        #         responses.append(output.cpu().numpy())\n",
        "        #\n",
        "        #     all_responses = np.concatenate(responses, axis=0)\n",
        "\n",
        "        # For now, return dummy data with expected shape\n",
        "        # Replace this with your actual model inference\n",
        "        dummy_response = np.zeros((stimulus.shape[0], 100))  # Example shape\n",
        "\n",
        "        return dummy_response\n",
        "\n",
        "    def get_metadata(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Return metadata about the model and its outputs.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict[str, Any]\n",
        "            Dictionary containing model metadata.\n",
        "        \"\"\"\n",
        "        # Load metadata file if available\n",
        "        metadata_path = os.path.join(\n",
        "                self.nest_dir,\n",
        "                'your_path') # Adjust filename format as needed\n",
        "\n",
        "        try:\n",
        "            metadata = np.load(metadata_path, allow_pickle=True).item()\n",
        "            return metadata\n",
        "        except Exception as e:\n",
        "            # If no metadata file exists, return basic info\n",
        "            return {\n",
        "                \"model_id\": self.MODEL_ID,\n",
        "                \"subject\": self.subject,\n",
        "                # Add any other relevant metadata\n",
        "            }\n",
        "\n",
        "    @classmethod\n",
        "    def get_model_id(cls) -> str:\n",
        "        \"\"\"\n",
        "        Return the model's unique identifier.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Model ID string from the YAML config.\n",
        "        \"\"\"\n",
        "        return cls.MODEL_ID\n",
        "\n",
        "    def cleanup(self) -> None:\n",
        "        \"\"\"\n",
        "        Release resources (e.g., GPU memory) when finished.\n",
        "        \"\"\"\n",
        "        if hasattr(self, 'model') and self.model is not None:\n",
        "            # Free GPU memory if using CUDA\n",
        "            if hasattr(self.model, 'to'):\n",
        "                self.model.to('cpu')\n",
        "\n",
        "            # Clear references\n",
        "            self.model = None\n",
        "\n",
        "            # Force CUDA cache clear if available\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# 4. How to Add a New Modality\n",
        "\n",
        "To extend NEST with a new recording modality (e.g., MEG), follow the steps below:\n",
        "\n",
        "### 1. Create a Folder\n",
        "Create a new directory under `nest/models/`:\n",
        "```bash\n",
        "nest/models/your_modality/\n",
        "```\n",
        "\n",
        "### 2. Add Your Model Files\n",
        "Inside the new folder, include:\n",
        "- `your_model.py` &mdash; your model implementation.\n",
        "- `__init__.py` &mdash; register your model by adding:\n",
        "  ```python\n",
        "  import nest.models.your_modality.your_model\n",
        "  ```\n",
        "\n",
        "### 3. Add a Model Card\n",
        "Create a YAML configuration file for your model and place it in:\n",
        "```bash\n",
        "nest/models/model_cards/your_model_id.yaml\n",
        "```\n",
        "\n",
        "### 4. Specify the Modality\n",
        "In both `your_model.py` and the YAML config file, define the modality name. For example:\n",
        "```yaml\n",
        "modality: \"your_modality\"\n",
        "```\n",
        "\n",
        "### 5. Register the Modality\n",
        "Finally, update `nest/models/__init__.py` to ensure your modality is loaded:\n",
        "```python\n",
        "import nest.models.your_modality\n",
        "```\n",
        "\n",
        "\n",
        "## Final Directory Structure\n",
        "\n",
        "```\n",
        "nest/\n",
        "├── models/\n",
        "│   ├── __init__.py\n",
        "│   ├── fmri/\n",
        "│   ├── eeg/\n",
        "│   ├── your_modality/\n",
        "│   │   ├── __init__.py\n",
        "│   │   └── your_model.py\n",
        "│   └── model_cards/\n",
        "│       └── your_model_id.yaml\n",
        "```\n"
      ],
      "metadata": {
        "id": "dwAOJr9u3bdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 5. Contributing to NEST\n",
        "\n",
        "We warmly welcome all contributions to the NEST toolbox and are happy for every addition that helps grow the community.\n",
        "\n",
        "If you would like to submit a model, you can use this toolkit to guide your implementation.\n",
        "\n",
        "## Code Quality\n",
        "- Include clear **docstrings** for all public methods.\n",
        "- Add **type hints** to improve code readability.\n",
        "- Implement **robust error handling** with informative messages.\n",
        "- Follow existing **NEST naming conventions**.\n",
        "- Be thorough with your **YAML configuration** and include as much relevant information as possible.\n",
        "- If available, feel free to add **performance details**\n",
        "\n",
        "## Testing\n",
        "- Test your model with various **input shapes** and **data types**.\n",
        "- Verify that **error handling** works as expected.\n",
        "- Check **resource usage** during and after model execution.\n",
        "- Ensure all required **metadata** is correctly provided.\n",
        "\n",
        "## How to Contribute\n",
        "\n",
        "If you would like to contribute your model back to NEST:\n",
        "\n",
        "1. **Fork** the NEST repository.\n",
        "2. **Create a branch** from the `development` branch.\n",
        "3. **Add your model** following this tutorial.\n",
        "4. **Submit a pull request** with:\n",
        "   - A clear description of your model.\n",
        "   - Example code showing how to run your model.\n",
        "   - Any relevant **citations** or **references**.\n",
        "\n",
        "We look forward to your contributions and are excited to see the creative ways the community expands NEST!\n",
        "\n"
      ],
      "metadata": {
        "id": "1EE_DWTZ-4Jo"
      }
    }
  ]
}