{"cells":[{"cell_type":"markdown","metadata":{"id":"2903FrDpACVU"},"source":["# Adding new models to BERG - Tutorial\n","\n","This tutorial will guide you through the process of **adding new models** to the [**Brain Encoding Response Generator (BERG)**](https://github.com/gifale95/BERG) — a resource consisting of trained encoding models of the brain and an accompanying Python package to generate in silico neural responses to stimuli of your choice.\n","\n","> **Note:** This tutorial focuses on adding the **model implementation code** to the BERG [GitHub repository](https://github.com/gifale95/BERG) — you will find information on how to upload the data at the bottom in Step 4.\n","\n","By the end of this tutorial, you will be able to plug your model into BERG and use it to generate in silico neural responses to arbitrary stimuli. We warmly welcome all contributions!\n","\n","<font color='red'><b>IMPORTANT:</b></font> If you wish to submit encoding models trained on a neural dataset already existing in BERG (e.g., NSD, THINGS EEG2), make sure that you prepare the encoding models' training/validation/testing neural responses using the code found in the [`01_prepare_data`](https://github.com/gifale95/BERG/tree/main/berg_creation_code/01_prepare_data) folder, and that you test your encoding models using the code found in the [`03_test_encoding_models`](https://github.com/gifale95/BERG/tree/main/berg_creation_code/03_test_encoding_models) folder. The testing code also generates the metadata that will accompany your encoding models.\n","\n","### How to Contribute\n","\n","If you would like to contribute your encoding model to BERG:\n","\n","1. **Fork** the BERG repository.\n","2. **Create a branch** from the `development` branch.\n","3. **Add your model code** following this tutorial.\n","4. **Submit a pull request** with:\n","   - A clear description of your model.\n","   - Example code showing how to run your model.\n","   - Any relevant **citations** or **references**.\n","\n","### Code Quality\n","- Include clear **docstrings** for all public methods.\n","- Add **type hints** to improve code readability.\n","- Implement **robust error handling** with informative messages.\n","- Follow existing **BERG naming conventions**.\n","- Be thorough with your **YAML configuration** and include as much relevant information as possible.\n","- If available, feel free to add **performance details**\n","\n","### Testing\n","- Test your model with various **input shapes** and **data types**.\n","- Verify that **error handling** works as expected.\n","- Check **resource usage** during and after model execution.\n","- Ensure all required **metadata** is correctly provided.\n","\n","---"]},{"cell_type":"markdown","source":["## 1 | Overview\n","\n","Adding a new model to BERG requires creating two main files:\n","\n","1. **A Python model file** — implements the model’s core logic (i.e., how it processes input stimuli to produce predicted neural responses) and defines a standard interface (i.e., functions like `predict()` that allow the model to interact with BERG).\n","2. **A YAML configuration file** — describes the model’s parameters and behavior, including information about the model architecture, training data, and training procedure.\n","\n","These two files work together to register your encoding model with BERG and make it compatible with BERG’s unified interface — a common structure that allows users to call any model in the same way, regardless of its internal details.\n","\n","---\n"],"metadata":{"id":"GUudNKIXgRPI"}},{"cell_type":"markdown","metadata":{"id":"4n3VUrd1MnSm"},"source":["## 2 | How to Implement a New Model into BERG\n","\n","This step-by-step guide walks you through the process of implementing a complete model, starting from the barebones template shown above.\n","\n","We will cover the following topics:\n","\n","1. **Determining where your model belongs in the BERG structure**\n","2. **Creating the YAML configuration file**\n","3. **Implementing the model class with all required components:**\n","   - Model registration  \n","   - Initialization and parameter validation  \n","   - Model loading  \n","   - In silico neural response generation  \n","   - Metadata access  \n","   - Resource cleanup  \n"]},{"cell_type":"markdown","metadata":{"id":"nk4SHF9T8YEk"},"source":["### 2.1 | Determining Your Model's Location in the GitHub Repository\n","\n","First, determine which data acquisition **modality** your model belongs to:\n","\n","- If it's an **fMRI model**, add it to:  \n","  `berg/models/fmri/`\n","\n","- If it's an **EEG model**, add it to:  \n","  `berg/models/eeg/`\n","\n","- If it's a **new data acquisition modality**, create a new directory:  \n","  `berg/models/your_new_modality/`\n","\n","  > **Note**: If you are adding a new data acquisition modality, there are a few additional considerations. These are discussed in **Step 3** below.\n","\n","Your corresponding **YAML configuration file** should go here:  \n","`berg/models/model_cards/your_model_id.yaml`"]},{"cell_type":"markdown","metadata":{"id":"S9QlN874PGAY"},"source":["---\n","\n","### 2.2 | Creating the YAML Configuration File\n","\n","In the BERG toolkit, you'll find a template YAML file [here](https://github.com/gifale95/BERG/blob/main/berg/models/model_cards/template.yaml).\n","\n","\n","This template serves as a guide for creating your model's configuration.\n","\n","Your YAML file is **crucial** because it:\n","\n","- Provides metadata about your model  \n","- Defines input/output specifications  \n","- Documents valid parameters and constraints  \n","- Is used for parameter validation in your model class  \n","- Generates model cards for end users  \n","\n","> Be as detailed as possible — this helps others understand how to work with your model.  \n","> **You can reference existing model YAML files as examples.**\n","\n","Here's what you need to include:\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ld8ZojZNPghr"},"source":["```yaml\n","# Template YAML file for BERG model specification\n","# Replace placeholder values with actual model information\n","\n","# Basic metadata\n","model_id: modality-dataset-model_type  # e.g., fmri-nsd-fwrf\n","modality: modality  # e.g., fmri, eeg, meg, ...\n","training_dataset: dataset_name\n","species: Human  # e.g., Human, Macaque, etc.\n","stimuli: Images  # e.g., Images, Sounds, Text, etc.\n","model_architecture: feature_extraction_method  # e.g., ViT-B/32, fwRF, etc.\n","creator: your_name\n","\n","# General description of the model\n","description: |\n","  Provide a concise but informative description of the model, including:\n","   - What kind of in silico neural responses it generates\n","   - What dataset it was trained on\n","   - The basic approach/architecture\n","   - Any notable characteristics or limitations\n","   Keep this to 3-5 sentences for readability.\n","\n","# Input stimulus information\n","input:\n","  type: \"numpy.ndarray\"  # or other appropriate type\n","  shape: [shape_description]  # e.g., [batch_size, 3, height, width]\n","  description: \"Brief description of input format\"\n","  constraints:\n","    - \"List any constraints on input values\"\n","    - \"e.g., value ranges, size requirements, etc.\"\n","\n","# Output information\n","output:\n","  type: \"numpy.ndarray\"  # or other appropriate type\n","  shape: [shape_description]  # e.g., [batch_size, n_voxels]\n","  description: \"Brief description of output format\"\n","  dimensions:\n","    - name: \"dimension_name\"\n","      description: \"What this dimension represents\"\n","    - name: \"dimension_name\"\n","      description: \"What this dimension represents\"\n","    # Add more dimensions as needed\n","\n","# Model parameters and their usage\n","parameters:\n","  # First parameter\n","  param_name:\n","    type: param_type  # e.g., int, str, float\n","    required: true/false\n","    valid_values: list_of_valid_values  # or range, or omit if not applicable\n","    default: default_value  # include if there's a default value\n","    example: example_value\n","    description: \"Description of what this parameter represents\"\n","    function: \"Which function uses this parameter: get_encoding_model, load_model, ..\"\n","\n","  # Selection parameter to define specific outputs (ROI, channels, timepoints, etc.)\n","  selection:\n","    type: dict\n","    required: true\n","    description: |\n","      Specifies which outputs to include in the in silico model responses.\n","      This parameter defines for which data the in silico responses should be generated\n","      (e.g., specific ROI, timepoints, channels, etc.)\n","    function: get_encoding_model\n","    properties:\n","      key_name:  # Replace with model-specific keys, e.g., \"roi\", \"channels\", \"timepoints\"\n","        type: any\n","        description: \"Description of Model-specific selection criterion.\"\n","        example: \"V1\"\n","\n","  # Add more parameters as needed\n","  param_name:\n","    type: param_type\n","    required: true/false\n","    valid_values: list_of_valid_values  # or range, or omit if not applicable\n","    default: default_value  # include if there's a default value\n","    example: example_value\n","    description: \"Description of what this parameter represents\"\n","    function: \"Which function uses this parameter\"\n","\n","# Performance metrics (if needed) and references\n","performance:\n","  metrics:\n","    - name: \"metric_name\"\n","      value: \"metric_value\"\n","      description: \"What this metric represents\"\n","    \n","    # Add more metrics as needed\n","    - name: \"metric_name\"\n","      value: \"metric_value\"\n","      description: \"What this metric represents\"\n","  \n","  plots: \"URL_to_performance_plots\"  # URL or path to visualizations\n","\n","# Add References here\n","references:\n","    - \"Citation for your model or training dataset\"\n","```"]},{"cell_type":"markdown","metadata":{"id":"YsPKENefR2GG"},"source":["### 2.3 | Implementing the Model Class\n","\n","Now we'll build the complete model implementation step by step.  \n","The required functions must be named **exactly as shown** to work with the `BaseModelInterface`.\n","\n","You are free to add additional helper functions as needed — but the core methods must be implemented.\n","\n","You can refer to existing models for concrete implementations:\n","\n","- [fMRI model example](https://github.com/gifale95/NEST/blob/main/nest/models/fmri/nsd_fwrf.py)\n","- [EEG model example](https://github.com/gifale95/NEST/blob/main/nest/models/eeg/things_eeg.py)\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"Ax7ne30Ez-jf"},"source":["#### 2.3.1 | Model Registration\n","\n","First, set up the model registration code that makes your model discoverable by the BERG toolkit.\n","\n","This code:\n","\n","1. Loads your model's configuration from the YAML file  \n","2. Registers your model with the BERG registry, making it discoverable  \n","3. Specifies the module path, class name, and modality"]},{"cell_type":"markdown","metadata":{"id":"dofNplJfdjDV"},"source":["```python\n","import os\n","import yaml\n","from berg.core.model_registry import register_model\n","\n","# Load model info from YAML\n","def load_model_info():\n","    yaml_path = os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n","    with open(os.path.abspath(yaml_path), \"r\") as f:\n","        return yaml.safe_load(f)\n","\n","# Load model_info once at the top\n","model_info = load_model_info()\n","\n","# Register this model with the registry using model_info\n","register_model(\n","    model_id=model_info[\"model_id\"],\n","    module_path=\"berg.models.your_modality.your_model_file\",  # Replace with actual path\n","    class_name=\"YourModelClass\",\n","    modality=model_info.get(\"modality\", \"your_modality\"),\n","    training_dataset=model_info.get(\"training_dataset\", \"your_dataset\"),\n","    yaml_path=os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",")\n","```"]},{"cell_type":"markdown","metadata":{"id":"dWnvGCZo0Jz-"},"source":["---\n","\n","#### 2.3.2 | Class Initialization and Parameter Validation\n","\n","Next, define your model class by inheriting from `BaseModelInterface` and implement the initialization logic.\n","\n","The initialization method:\n","\n","1. Stores user-provided parameters (e.g., subject ID, device, BERG directory)  \n","2. Validates parameters against the specifications in the YAML file  \n","3. Sets up the compute device (CPU or GPU)  \n","4. Can process additional model-specific parameters through `**kwargs`\n","\n","\n","Most importantly, you can include a `selection` parameter to specify which parts of the model output should be returned.  \n","This is useful for selecting specific brain regions (e.g., \"V1\"), timepoints, or channels from the full in silico response.  \n","It allows users to work with only the subset of data relevant to their analysis, reducing memory usage and improving flexibility.  \n","The structure and valid values of this parameter should be defined in the model’s YAML configuration file (see above)."]},{"cell_type":"markdown","metadata":{"id":"fNM7j5cph8kz"},"source":["\n","```python\n","class YourModelClass(BaseModelInterface):\n","    \"\"\"\n","    Your model description here. Explain what this model does, what\n","    in silico neural responses it generates, and any other important details.\n","    \"\"\"\n","    \n","    MODEL_ID = model_info[\"model_id\"]\n","    # Extract any validation info from model_info\n","    VALID_SUBJECTS = model_info[\"parameters\"][\"subject\"][\"valid_values\"]\n","    \n","    def __init__(self, subject: int, selection: Dict, device: str = \"auto\", berg_dir: Optional[str] = None, **kwargs):\n","        \"\"\"\n","        Initialize your model with the required parameters.\n","        \n","        Parameters\n","        ----------\n","        subject : int\n","            Subject ID for subject-specific models.\n","        selection : dict\n","            Specifies which outputs to include in the model responses\n","            (ROI, Time interval, ...)\n","        device : str\n","            Device to run the model on ('cpu', 'cuda', or 'auto').\n","        berg_dir : str, optional\n","            Path to the BERG directory.\n","        **kwargs\n","            Additional model-specific parameters.\n","        \"\"\"\n","        self.subject = subject\n","        self.berg_dir = berg_dir\n","        self.model = None\n","        self.selection = selection\n","        self._validate_parameters()\n","        \n","        # Select device\n","        if device == \"auto\":\n","            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.device = device\n","        \n","        # Store any additional parameters\n","        # self.your_param = kwargs.get('your_param', default_value)\n","\n","    def _validate_parameters(self):\n","        \"\"\"\n","        Validate the input parameters against the model specs.\n","        \"\"\"\n","        if self.subject not in self.VALID_SUBJECTS:\n","            raise InvalidParameterError(\n","                f\"Subject must be one of {self.VALID_SUBJECTS}, got {self.subject}\"\n","            )\n","\n","        # For selection Paramter if available\n","        if self.selection is not None:\n","            # Validate selection keys\n","            validate_selection_keys(self.selection, self.SELECTION_KEYS)\n","\n","            # Individual validations (example of ROIs)\n","            if \"roi\" in self.selection:\n","                self.roi = validate_roi(\n","                    self.selection[\"roi\"], self.VALID_ROIS\n","                )\n","        # Ensure selection is provided\n","        else:\n","            raise InvalidParameterError(\"Parameter 'selection' is required but was not provided\")\n","        \n","        # Add any other parameter validation here\n","```"]},{"cell_type":"markdown","metadata":{"id":"pTiyAfrv0OWm"},"source":["---\n","#### 2.3.3 | Loading the Model\n","\n","Next, implement the `load_model()` method, which handles loading model weights and preparing the model for inference.\n","\n","This method:\n","\n","1. Constructs the file path to your model weights using a consistent directory structure  \n","2. Loads the model architecture and weights (implementation will vary based on your model type)  \n","3. Moves the model to the appropriate device (CPU or GPU)  \n","4. Sets the model to evaluation mode  \n","5. Stores the loaded model in a class variable (e.g., `self.model`) for use by other methods\n","\n","> If you implement the `selection parameter` (`self.selection`) to select specific ROIs or timeintervals, make sure that given those parameters only those models are loaded to save memory and computation time!\n"]},{"cell_type":"markdown","metadata":{"id":"sXXdjkLgk3EA"},"source":["\n","```python\n","\n","    def load_model(self) -> None:\n","        \"\"\"\n","        Load model weights and prepare for inference.\n","        \"\"\"\n","        try:\n","            # Build paths to model weights\n","            weights_path = os.path.join(\n","                self.berg_dir,\n","                'your_path') # Adjust filename format as needed\n","            \n","            # Load your model here\n","            # Example with PyTorch:\n","            # self.model = YourModelArchitecture()\n","            # self.model.load_state_dict(torch.load(weights_path, map_location=torch.device(self.device)))\n","            # self.model.to(self.device)\n","            # self.model.eval()\n","            \n","            print(f\"Model loaded on {self.device} for subject {self.subject}\")\n","        \n","        except Exception as e:\n","            raise ModelLoadError(f\"Failed to load model: {str(e)}\")\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"4AqmDu400QxE"},"source":["---\n","#### 2.3.4 | Generating in silico neural responses\n","\n","The `generate_response()` method is the core functionality that produces in silico neural responses from input stimuli:\n","\n","This method:\n","\n","1. Validates the input stimulus to ensure it meets requirements  \n","2. Preprocesses the stimulus if needed (e.g., normalization, resizing)  \n","3. Runs the model inference, typically in batches to manage memory usage  \n","4. Collects and formats the response data  \n","5. Returns the in silico neural responses as a NumPy array  \n","\n","Customize this method based on your model's specific requirements and output format.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pukmJ-rundzw"},"source":["\n","```python\n","    def generate_response(\n","        self,\n","        stimulus: np.ndarray,\n","        **kwargs) -> np.ndarray:\n","        \"\"\"\n","        Generate in silico neural responses for given stimuli.\n","        \n","        Parameters\n","        ----------\n","        stimulus : np.ndarray\n","            Input stimulus array. Typically has shape (batch_size, channels, height, width)\n","            for image stimuli, but requirements vary by model.\n","        **kwargs\n","            Additional model-specific parameters for in silico response generation.\n","        \n","        Returns\n","        -------\n","        np.ndarray\n","            Simulated in silico neural responses. Shape depends on your model's output.\n","        \"\"\"\n","        # Validate stimulus\n","        if not isinstance(stimulus, np.ndarray) or len(stimulus.shape) != 4:\n","            raise StimulusError(\n","                \"Stimulus must be a 4D numpy array (batch, channels, height, width)\"\n","            )\n","        \n","        # Preprocess stimulus if needed\n","        preprocessed_stimulus = preprocess(stimulus)\n","        \n","        # Generate in silico responses\n","        with torch.no_grad():\n","            batch_size = 100  # Adjust as needed\n","            responses = []\n","            \n","            for i in range(0, len(stimulus), batch_size):\n","                batch = torch.from_numpy(stimulus[i:i+batch_size]).to(self.device)\n","                output = self.model(batch)\n","                responses.append(output.cpu().numpy())\n","            \n","            all_responses = np.concatenate(responses, axis=0)\n","        \n","        return all_responses\n","```"]},{"cell_type":"markdown","metadata":{"id":"CsEkzHHX0TO1"},"source":["#### 2.3.5 | Accessing Metadata\n","\n","The `get_metadata()` method provides information about your encoding model and the shape or structure of its in silico responses.  \n","This might include voxel indices, channel names, ROIs, timepoint definitions, or any other output-relevant detail.\n","\n","To support metadata access *without having to load the full model*, BERG allows retrieving metadata in two ways:\n","\n","- **During encoding**:  \n","  `_, metadata = berg_object.encode(model_id, stimuli, return_metadata=True)`\n","\n","- **Directly through the BERG API** (without loading the model):  \n","  `metadata = berg_object.get_model_metadata(model_id, subject=..., roi=...)`\n","\n","To support this flexibility, you must implement a `@classmethod get_metadata()` in your model class.  \n","This method can extract metadata either from a provided model instance or from the input parameters alone.\n","\n","Below is a template showing the recommended structure.  \n","You can adapt it depending on whether your model uses ROIs, timepoints, or other selection parameters.\n","\n","This is the most complicated function to implement but you should be able to \"blindly\" follow this template and just add your missing variables. Feel free to refer to existing models for concrete implementations:\n","\n","- [fMRI model example](https://github.com/gifale95/BERG/blob/main/berg/models/fmri/nsd_fwrf.py)\n","- [EEG model example](https://github.com/gifale95/BERG/blob/main/berg/models/eeg/things_eeg.py)\n","\n","```python\n","@classmethod\n","def get_metadata(cls, berg_dir=None, subject=None, model_instance=None, roi=None, **kwargs) -> Dict[str, Any]:\n","    \"\"\"\n","    Retrieve metadata for the model.\n","\n","    Parameters\n","    ----------\n","    berg_dir : str\n","        Path to the BERG directory where metadata is stored.\n","    subject : int\n","        Subject number.\n","    model_instance : BaseModelInterface, optional\n","        If provided, parameters can be extracted directly from the model instance.\n","    roi : str, optional\n","        Region of interest (if applicable).\n","    **kwargs\n","        Additional model-specific parameters.\n","\n","    Returns\n","    -------\n","    Dict[str, Any]\n","        Metadata dictionary.\n","    \"\"\"\n","    \n","    # Extract parameters from instance if available\n","    if model_instance is not None:\n","        berg_dir = model_instance.berg_dir\n","        subject = model_instance.subject\n","        roi = getattr(model_instance, \"roi\", roi)\n","\n","    # Also allow metadata retrieval from class instance\n","    elif not isinstance(cls, type) and isinstance(cls, BaseModelInterface):\n","        berg_dir = cls.berg_dir\n","        subject = cls.subject\n","        roi = getattr(cls, \"roi\", roi)\n","\n","    # Validate required parameters\n","    missing = []\n","    if berg_dir is None: missing.append(\"berg_dir\")\n","    if subject is None: missing.append(\"subject\")\n","    if roi is None and \"VALID_ROIS\" in dir(cls): missing.append(\"roi\")\n","    \n","    if missing:\n","        raise InvalidParameterError(f\"Required parameters missing: {', '.join(missing)}\")\n","\n","    # Optional: validate against allowed values\n","    validate_subject(subject, cls.VALID_SUBJECTS)\n","    if roi is not None and hasattr(cls, \"VALID_ROIS\"):\n","        validate_roi(roi, cls.VALID_ROIS)\n","\n","    # Build metadata path\n","    filename = os.path.join(\n","        berg_dir,\n","        \"encoding_models\",\n","        \"modality-<your_modality>\",               # e.g., modality-fmri\n","        \"train_dataset-<your_dataset>\",           # e.g., train_dataset-nsd\n","        \"model-<your_model_id>\",                  # e.g., model-vit_b_32\n","        \"metadata\",\n","        f\"metadata_sub-{subject:02d}\" + (f\"_roi-{roi}\" if roi else \"\") + \".npy\"\n","    )\n","\n","    # Load metadata\n","    if os.path.exists(filename):\n","        metadata = np.load(filename, allow_pickle=True).item()\n","        return metadata\n","    else:\n","        raise FileNotFoundError(f\"Metadata file not found at: {filename}\")\n","  ```"]},{"cell_type":"markdown","metadata":{"id":"pimREama0V23"},"source":["---\n","#### 2.3.6 | Auxiliary Methods\n","\n","Finally, implement these required auxiliary methods.\n","\n","The `get_model_id()` method:\n","\n","1. Returns the unique identifier for your model  \n","2. Is used by the BERG registry to identify the model  \n","\n","The `cleanup()` method:\n","\n","1. Releases resources (especially GPU memory)  \n","2. Is important for preventing memory leaks when working with multiple models  \n","3. Should clean up any large objects or references\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Rh_p0NzPpgBc"},"source":["\n","```python\n","    @classmethod\n","    def get_model_id(cls) -> str:\n","        \"\"\"\n","        Return the model's unique identifier.\n","        \n","        Returns\n","        -------\n","        str\n","            Model ID string from the YAML config.\n","        \"\"\"\n","        return cls.MODEL_ID\n","    \n","    def cleanup(self) -> None:\n","        \"\"\"\n","        Release resources (e.g., GPU memory) when finished.\n","        \"\"\"\n","        if hasattr(self, 'model') and self.model is not None:\n","            # Free GPU memory if using CUDA\n","            if hasattr(self.model, 'to'):\n","                self.model.to('cpu')\n","            \n","            # Clear references\n","            self.model = None\n","            \n","            # Force CUDA cache clear if available\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()\n","  ```"]},{"cell_type":"markdown","metadata":{"id":"fpl76IUZxXcI"},"source":["---\n","\n","#### 2.3.7 | Complete Implementation Example\n","\n","For more detailed examples, you can refer to existing models:\n","\n","- [fMRI model example](https://github.com/gifale95/NEST/blob/main/nest/models/fmri/nsd_fwrf.py)\n","- [EEG model example](https://github.com/gifale95/NEST/blob/main/nest/models/eeg/things_eeg.py)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhZS7Kh__-DX"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import yaml\n","from typing import Dict, Any, Optional\n","\n","from berg.interfaces.base_model import BaseModelInterface\n","from berg.core.model_registry import register_model\n","from berg.core.exceptions import ModelLoadError, InvalidParameterError, StimulusError\n","\n","# Load model info from YAML\n","def load_model_info():\n","    yaml_path = os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n","    with open(os.path.abspath(yaml_path), \"r\") as f:\n","        return yaml.safe_load(f)\n","\n","# Load model_info once at the top\n","model_info = load_model_info()\n","\n","# Register this model with the registry using model_info\n","register_model(\n","    model_id=model_info[\"model_id\"],\n","    module_path=\"berg.models.your_modality.your_model_file\",  # Replace with actual path\n","    class_name=\"YourModelClass\",\n","    modality=model_info.get(\"modality\", \"your_modality\"),\n","    training_dataset=model_info.get(\"training_dataset\", \"your_dataset\"),\n","    yaml_path=os.path.join(os.path.dirname(__file__), \"..\", \"model_cards\", \"your_model_id.yaml\")\n",")\n","\n","\n","\n","\n","class YourModelClass(BaseModelInterface):\n","    \"\"\"\n","    Your model description here. Explain what this model does, what\n","    in silico neural responses it generates, and any other important details.\n","    \"\"\"\n","\n","    MODEL_ID = model_info[\"model_id\"]\n","    # Extract any validation info from model_info\n","    VALID_SUBJECTS = model_info[\"parameters\"][\"subject\"][\"valid_values\"]\n","\n","    def __init__(self, subject: int, selection: Dict, device: str = \"auto\", berg_dir: Optional[str] = None, **kwargs):\n","        \"\"\"\n","        Initialize your model with the required parameters.\n","\n","        Parameters\n","        ----------\n","        subject : int\n","            Subject ID for subject-specific models.\n","        selection : dict\n","            Specifies which outputs to include in the model responses\n","            (ROI, Time interval, ...)\n","        device : str\n","            Device to run the model on ('cpu', 'cuda', or 'auto').\n","        berg_dir : str, optional\n","            Path to the BERG directory.\n","        **kwargs\n","            Additional model-specific parameters.\n","        \"\"\"\n","        self.subject = subject\n","        self.berg_dir = berg_dir\n","        self.model = None\n","        self.selection = selection\n","        self._validate_parameters()\n","\n","        # Select device\n","        if device == \"auto\":\n","            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.device = device\n","\n","        # Store any additional parameters\n","        # self.your_param = kwargs.get('your_param', default_value)\n","\n","    def _validate_parameters(self):\n","        \"\"\"\n","        Validate the input parameters against the model specs.\n","        \"\"\"\n","        if self.subject not in self.VALID_SUBJECTS:\n","            raise InvalidParameterError(\n","                f\"Subject must be one of {self.VALID_SUBJECTS}, got {self.subject}\"\n","            )\n","\n","        # For selection Paramter if available\n","        if self.selection is not None:\n","            # Validate selection keys\n","            validate_selection_keys(self.selection, self.SELECTION_KEYS)\n","\n","            # Individual validations (example of ROIs)\n","            if \"roi\" in self.selection:\n","                self.roi = validate_roi(\n","                    self.selection[\"roi\"], self.VALID_ROIS\n","                )\n","        # Ensure selection is provided\n","        else:\n","            raise InvalidParameterError(\"Parameter 'selection' is required but was not provided\")\n","\n","        # Add any other parameter validation here\n","\n","    def load_model(self) -> None:\n","        \"\"\"\n","        Load model weights and prepare for inference.\n","        \"\"\"\n","        try:\n","            # Build paths to model weights\n","            weights_path = os.path.join(\n","                self.berg_dir,\n","                'your_path') # Adjust filename format as needed\n","\n","            # Load your model here\n","            # Example with PyTorch:\n","            # self.model = YourModelArchitecture()\n","            # self.model.load_state_dict(torch.load(weights_path, map_location=torch.device(self.device)))\n","            # self.model.to(self.device)\n","            # self.model.eval()\n","\n","            print(f\"Model loaded on {self.device} for subject {self.subject}\")\n","\n","        except Exception as e:\n","            raise ModelLoadError(f\"Failed to load model: {str(e)}\")\n","\n","    def generate_response(\n","        self,\n","        stimulus: np.ndarray,\n","        **kwargs) -> np.ndarray:\n","        \"\"\"\n","        Generate in silico neural responses for given stimuli.\n","\n","        Parameters\n","        ----------\n","        stimulus : np.ndarray\n","            Input stimulus array. Typically has shape (batch_size, channels, height, width)\n","            for image stimuli, but requirements vary by model.\n","        **kwargs\n","            Additional model-specific parameters for in silico response generation.\n","\n","        Returns\n","        -------\n","        np.ndarray\n","            Simulated in silico neural responses. Shape depends on your model's output.\n","        \"\"\"\n","        # Validate stimulus\n","        if not isinstance(stimulus, np.ndarray) or len(stimulus.shape) != 4:\n","            raise StimulusError(\n","                \"Stimulus must be a 4D numpy array (batch, channels, height, width)\"\n","            )\n","\n","        # Preprocess stimulus if needed\n","        preprocessed_stimulus = preprocess(stimulus)\n","\n","        # Generate in silico responses\n","        with torch.no_grad():\n","            batch_size = 100  # Adjust as needed\n","            responses = []\n","\n","            for i in range(0, len(stimulus), batch_size):\n","                batch = torch.from_numpy(stimulus[i:i+batch_size]).to(self.device)\n","                output = self.model(batch)\n","                responses.append(output.cpu().numpy())\n","\n","            all_responses = np.concatenate(responses, axis=0)\n","\n","        return all_responses\n","\n","\n","\n","    @classmethod\n","    def get_metadata(cls, berg_dir=None, subject=None, model_instance=None, roi=None, **kwargs) -> Dict[str, Any]:\n","        \"\"\"\n","        Retrieve metadata for the model.\n","\n","        Parameters\n","        ----------\n","        berg_dir : str\n","            Path to the BERG directory where metadata is stored.\n","        subject : int\n","            Subject number.\n","        model_instance : BaseModelInterface, optional\n","            If provided, parameters can be extracted directly from the model instance.\n","        roi : str, optional\n","            Region of interest (if applicable).\n","        **kwargs\n","            Additional model-specific parameters.\n","\n","        Returns\n","        -------\n","        Dict[str, Any]\n","            Metadata dictionary.\n","        \"\"\"\n","\n","        # Extract parameters from instance if available\n","        if model_instance is not None:\n","            berg_dir = model_instance.berg_dir\n","            subject = model_instance.subject\n","            roi = getattr(model_instance, \"roi\", roi)\n","\n","        # Also allow metadata retrieval from class instance\n","        elif not isinstance(cls, type) and isinstance(cls, BaseModelInterface):\n","            berg_dir = cls.berg_dir\n","            subject = cls.subject\n","            roi = getattr(cls, \"roi\", roi)\n","\n","        # Validate required parameters\n","        missing = []\n","        if berg_dir is None: missing.append(\"berg_dir\")\n","        if subject is None: missing.append(\"subject\")\n","        if roi is None and \"VALID_ROIS\" in dir(cls): missing.append(\"roi\")\n","\n","        if missing:\n","            raise InvalidParameterError(f\"Required parameters missing: {', '.join(missing)}\")\n","\n","        # Optional: validate against allowed values\n","        validate_subject(subject, cls.VALID_SUBJECTS)\n","        if roi is not None and hasattr(cls, \"VALID_ROIS\"):\n","            validate_roi(roi, cls.VALID_ROIS)\n","\n","        # Build metadata path\n","        filename = os.path.join(\n","            berg_dir,\n","            \"encoding_models\",\n","            \"modality-<your_modality>\",               # e.g., modality-fmri\n","            \"train_dataset-<your_dataset>\",           # e.g., train_dataset-nsd\n","            \"model-<your_model_id>\",                  # e.g., model-vit_b_32\n","            \"metadata\",\n","            f\"metadata_sub-{subject:02d}\" + (f\"_roi-{roi}\" if roi else \"\") + \".npy\"\n","        )\n","\n","        # Load metadata\n","        if os.path.exists(filename):\n","            metadata = np.load(filename, allow_pickle=True).item()\n","            return metadata\n","        else:\n","            raise FileNotFoundError(f\"Metadata file not found at: {filename}\")\n","\n","    @classmethod\n","    def get_model_id(cls) -> str:\n","        \"\"\"\n","        Return the model's unique identifier.\n","\n","        Returns\n","        -------\n","        str\n","            Model ID string from the YAML config.\n","        \"\"\"\n","        return cls.MODEL_ID\n","\n","    def cleanup(self) -> None:\n","        \"\"\"\n","        Release resources (e.g., GPU memory) when finished.\n","        \"\"\"\n","        if hasattr(self, 'model') and self.model is not None:\n","            # Free GPU memory if using CUDA\n","            if hasattr(self.model, 'to'):\n","                self.model.to('cpu')\n","\n","            # Clear references\n","            self.model = None\n","\n","            # Force CUDA cache clear if available\n","            if torch.cuda.is_available():\n","                torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"dwAOJr9u3bdo"},"source":["---\n","\n","## 3 | Adding a New Modality\n","\n","To extend BERG with a new data acquisition modality (e.g., MEG), follow the steps below:\n","\n","### 1. Create a Folder\n","Create a new directory under `berg/models/`:\n","```bash\n","berg/models/your_modality/\n","```\n","\n","### 2. Add Your Model Files\n","Inside the new folder, include:\n","- `your_model.py` &mdash; your model implementation.\n","- `__init__.py` &mdash; register your model by adding:\n","  ```python\n","  import berg.models.your_modality.your_model\n","  ```\n","\n","### 3. Add a Model Card\n","Create a YAML configuration file for your model and place it in:\n","```bash\n","berg/models/model_cards/your_model_id.yaml\n","```\n","\n","### 4. Specify the Modality\n","In both `your_model.py` and the YAML config file, define the modality name. For example:\n","```yaml\n","modality: \"your_modality\"\n","```\n","\n","### 5. Register the Modality\n","Finally, update `berg/models/__init__.py` to ensure your modality is loaded:\n","```python\n","import berg.models.your_modality\n","```\n","\n","\n","## Final Directory Structure\n","\n","```\n","berg/\n","├── models/\n","│   ├── __init__.py\n","│   ├── fmri/\n","│   ├── eeg/\n","│   ├── your_modality/\n","│   │   ├── __init__.py\n","│   │   └── your_model.py\n","│   └── model_cards/\n","│       └── your_model_id.yaml\n","```\n"]},{"cell_type":"markdown","source":["---\n","## 4 | Uploading Your Model Weights\n","\n","After implementing and testing your model, the final step is to upload the trained weights and associated metadata so that others can use your model through BERG.\n","\n","### Step 1: Follow the BERG Directory Structure\n","\n","Please organize your files following the official BERG dataset structure, as described in the [BERG documentation](https://brain-encoding-response-generator.readthedocs.io/en/latest/data_storage.html#berg-dataset-structure):\n","\n","```python\n","brain-encoding-response-generator/\n","├── encoding_models/\n","│   ├── modality-{modality}/\n","│   │   ├── train_dataset-{dataset}/\n","│   │   │   └── model-{model}/\n","│   │   │       ├── encoding_models_accuracy/\n","│   │   │       ├── encoding_models_weights/\n","│   │   │       └── metadata/\n","└── berg_tutorials/\n","```\n","\n","\n","Replace `{modality}`, `{dataset}`, and `{model}` with the appropriate values (e.g., `modality-fmri`, `train_dataset-nsd`, `model-fwrf`).\n","\n","Each model directory must contain the following subfolders:\n","- `encoding_models_weights/`: your model weights (e.g., `.pth`, `.npz`, etc.)\n","- `encoding_models_accuracy/`: performance metrics or evaluation results\n","- `metadata/`: precomputed metadata files returned by your `get_metadata()` method\n","\n","### Step 2: Create a Zip Archive\n","\n","Once the directory is correctly structured, compress the entire `brain-encoding-response-generator/` folder into a `.zip` archive.\n","\n","### Step 3: Upload to a Cloud Service\n","\n","Upload the `.zip` file to a cloud storage provider that provides a **public direct download link**. Make sure that access permissions are set to **public or viewable by link**.\n","\n","### Step 4: Submit a Pull Request\n","\n","Include the public link to your `.zip` archive in your pull request.  \n","For detailed instructions on contributing to BERG, please refer to the official guide: [How to contribute](https://neural-encoding-simulation-toolkit.readthedocs.io/en/latest/contribution.html)\n"],"metadata":{"id":"FIhRAycXx2mU"}}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}