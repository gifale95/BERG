{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_dir = \"neural_encoding_simulation_toolkit\" \n",
    "test_images = \"tutorial_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchvision import transforms as trn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "images_dir = os.path.join(test_images)\n",
    "images_list = os.listdir(images_dir)\n",
    "images_list.sort()\n",
    "    \n",
    "images = []\n",
    "for img in tqdm(images_list):\n",
    "    img_dir = os.path.join(images_dir, img)\n",
    "    img = Image.open(img_dir).convert('RGB')\n",
    "    # Center crop the images to square format, and resize them\n",
    "    transform = trn.Compose([\n",
    "        trn.CenterCrop(min(img.size)),\n",
    "        trn.Resize((227,227))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    img = np.asarray(img)\n",
    "    img = img.transpose(2,0,1)\n",
    "    images.append(img)\n",
    "images = np.asarray(images)\n",
    "\n",
    "# Print the images dimensions\n",
    "print('\\n\\nImages shape:')\n",
    "print(images.shape)\n",
    "print('(Batch size Ã— 3 RGB Channels x Width x Height)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run the code in general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nest import NEST\n",
    "\n",
    "nest = NEST(nest_dir=nest_dir)\n",
    "\n",
    "# List all available models and their versions\n",
    "available_models = nest.list_models()\n",
    "print(f\"Available models: {available_models}\")\n",
    "\n",
    "# See what modalities are available\n",
    "catalog = nest.get_model_catalog(print_format=True)\n",
    "print(f\"Model Catalog as Dict:: {catalog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Encoding Model\n",
    "fwrf_model = nest.get_encoding_model(\"fmri-nsd-fwrf\", \n",
    "                                     subject=1, \n",
    "                                     device=\"cpu\",\n",
    "                                     selection={\"roi\": \"V1\"})\n",
    "\n",
    "\n",
    "eeg_model = nest.get_encoding_model(\"eeg-things_eeg_2-vit_b_32\", \n",
    "                                    subject=1,\n",
    "                                    device=\"auto\")\n",
    "\n",
    "\n",
    "fwrf_silico = nest.encode(fwrf_model, images)\n",
    "eeg_silico, eeg_metadata = nest.encode(eeg_model, images,return_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fwRF Model in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nest import NEST\n",
    "nest = NEST(nest_dir=nest_dir)\n",
    "\n",
    "# Choose a model of interest\n",
    "model_id = \"fmri-nsd-fwrf\"  # Example model ID\n",
    "\n",
    "# Get comprehensive model information\n",
    "model_info = nest.describe(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Encoding Model\n",
    "fwrf_model = nest.get_encoding_model(\"fmri-nsd-fwrf\", \n",
    "                                     subject=1, \n",
    "                                     selection={\"roi\": \"V1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode images\n",
    "nest.encode(fwrf_model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode images and return metadata\n",
    "nest.encode(fwrf_model, images, return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest.get_metadata_from_id(\"fmri-nsd-fwrf\", \n",
    "                          subject=1,\n",
    "                          roi=\"V1\")\n",
    "\n",
    "fwrf_model = nest.get_encoding_model(\"fmri-nsd-fwrf\", \n",
    "                                     subject=1,\n",
    "                                     roi=\"V1\")\n",
    "fwrf_model.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just return metadata of model\n",
    "fwrf_model.get_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing EEG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nest import NEST\n",
    "nest = NEST(nest_dir=nest_dir)\n",
    "\n",
    "\n",
    "eeg_model = nest.get_encoding_model(\"eeg-things_eeg_2-vit_b_32\", \n",
    "                                    subject=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest.encode(eeg_model, images,return_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Selection Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeg_model = nest.get_encoding_model(\"eeg-things_eeg_2-vit_b_32\", \n",
    "                                    subject=1,\n",
    "                                    device=\"auto\",\n",
    "                                    selection={\"channels\": ['F7']})\n",
    "\n",
    "eeg_silico = nest.encode(eeg_model, images)\n",
    "\n",
    "print(eeg_silico.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
    "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, \n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
    "          0, 0, 0, 0, 0, 0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0]\n",
    "\n",
    "\n",
    "eeg_model = nest.get_encoding_model(\"eeg-things_eeg_2-vit_b_32\", \n",
    "                                    subject=1,\n",
    "                                    device=\"auto\",\n",
    "                                    selection={\"channels\": ['F7'],\n",
    "                                               \"timepoints\": vector})\n",
    "\n",
    "eeg_silico = nest.encode(eeg_model, images)\n",
    "\n",
    "print(eeg_silico.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can describe a model in two ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = nest.describe(\"eeg-things_eeg_2-vit_b_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = eeg_model.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if Metadataretrieval works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nest import NEST\n",
    "nest = NEST(nest_dir=nest_dir)\n",
    "\n",
    "\n",
    "eeg_model = nest.get_encoding_model(\"eeg-things_eeg_2-vit_b_32\", \n",
    "                                    subject=1)\n",
    "eeg_silico_total, eeg_metadata = nest.encode(eeg_model, images, return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 8\n",
    "\n",
    "print(eeg_metadata[\"eeg\"][\"ch_names\"][channel])\n",
    "print(eeg_silico_total.shape)\n",
    "eeg_silico_total[:,:,channel,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nest import NEST\n",
    "nest = NEST(nest_dir=nest_dir)\n",
    "\n",
    "\n",
    "eeg_model = nest.get_encoding_model(\"eeg-things_eeg_2-vit_b_32\", \n",
    "                                    subject=1,\n",
    "                                    selection={\"channels\": [eeg_metadata[\"eeg\"][\"ch_names\"][channel]]})\n",
    "eeg_silico = nest.encode(eeg_model, images)\n",
    "\n",
    "print(eeg_silico.shape)\n",
    "\n",
    "np.all(eeg_silico == eeg_silico_total[:,:,channel,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
